{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch all meals with nutrition facts and ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "from bs4 import BeautifulSoup\n",
    "from contextlib import closing\n",
    "from requests import get\n",
    "from requests.exceptions import RequestException\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import html5lib\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from datetime import datetime as dt\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_driver():    \n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = get_driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename = '/home/hardik/BMI-based-food-recommendation/scraping_logs.log', filemode='a', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('test')\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(url):\n",
    "    \"\"\"This function makes a GET Request to the url specified.\n",
    "    This gets the raw HTML content if there is a good response.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        resp = get(url, stream=True, timeout=30)\n",
    "        if resp.status_code == 200:\n",
    "            return resp.content\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        logging.exception(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_food_name_url(parsed_data_html):\n",
    "    \n",
    "    # Convert html data into beautifulSoup format using html parser\n",
    "    parsed_data_bs = BeautifulSoup(parsed_data_html, \"html.parser\")\n",
    "\n",
    "    # Search for table with id = 'myTable' and extract each row of data\n",
    "    parsed_data_class = parsed_data_bs.findAll('div', {'class': 'row food_result'})\n",
    "    food_list = []\n",
    "    for each_row in parsed_data_class:\n",
    "        link = each_row.find('a')\n",
    "        nutrition_link = link['href']\n",
    "        food_name = link.find('div', {'class':'result_name'})\n",
    "        nutrients = link.findAll('div', {'class':'nutrient_cell'})\n",
    "        nuts = []\n",
    "        for each_nutrient in nutrients:\n",
    "            each_nutrient = each_nutrient.text.strip().split(' ')\n",
    "            if len(each_nutrient)!=1:\n",
    "                each_nut = each_nutrient[0][:-1] + ' ' + each_nutrient[-1]\n",
    "            else:\n",
    "                each_nut = each_nutrient[0]\n",
    "            nuts.append(each_nut)\n",
    "        food_list.append([food_name.text.strip(), nutrition_link])\n",
    "        food_list[-1].extend(nuts)\n",
    "    return food_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.eatthismuch.com/food/browse/?q=&type=recipe&group=Pasta&page='\n",
    "url = 'https://www.eatthismuch.com/food/browse/?q=&type=recipe&group=Sandwiches&page='\n",
    "url = 'https://www.eatthismuch.com/food/browse/?q=&type=recipe&group=Mostly%20meat&page='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_list = []\n",
    "for i in range(1,36):\n",
    "    current_page_url = url + str(i)\n",
    "    parsed_data_html = get_html(current_page_url)\n",
    "    food_list.extend(get_food_name_url(parsed_data_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "pastas_list = pd.DataFrame(food_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "sandwich_list = pd.DataFrame(food_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "meat_list = pd.DataFrame(food_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "pastas_list['type'] = 'pasta'\n",
    "sandwich_list['type'] = 'sandwich'\n",
    "meat_list['type'] = 'meat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "food = pd.concat([pastas_list, sandwich_list, meat_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "food.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "food.columns = ['food_name', 'food_url', 'Calories', 'Carbs', 'Fat', 'Protein', 'Fiber', 'type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "food.to_csv('food_list.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_array = list(food.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_food_ingredients(parsed_data_html):\n",
    "    parsed_data_bs = BeautifulSoup(parsed_data_html, \"html.parser\")\n",
    "    # Search for table with id = 'myTable' and extract each row of data\n",
    "    parsed_data_class = parsed_data_bs.find('div', {'class': 'ingredients_box'})\n",
    "    try:\n",
    "        ingredients_html = parsed_data_class.findAll('li')\n",
    "        ingredient_list = []\n",
    "        for each_ingredient in ingredients_html:\n",
    "            ingredient = each_ingredient.find('div', {'class':'print_name'}).text\n",
    "            ingredient_list.append(ingredient)\n",
    "        return ', '.join(ingredient_list)\n",
    "    except AttributeError as e:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.eatthismuch.com'\n",
    "for index in range(571,len(food_array)):\n",
    "    current_page_url = url + food_array[index][1]\n",
    "    driver.get(current_page_url)\n",
    "    time.sleep(5)\n",
    "    parsed_data_html = driver.page_source\n",
    "    ingredients = get_food_ingredients(parsed_data_html)\n",
    "    ingredients_list.append([food_array[index][1], ingredients])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredient = pd.DataFrame(ingredients_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredient.columns = ['foodurl', 'ingredients']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_food = pd.merge(food, ingredient, left_on = 'food_url', right_on = 'foodurl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_food.drop(['foodurl'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_food.to_csv('food_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
